# 需求文档：daily-arXiv - AI驱动的论文母题筛选器

## 介绍

### 背景

科研人员每天面临信息过载：arXiv 每天发布 100+ 篇论文，手动筛选耗时 30 分钟以上。现有的解决方案存在以下问题：

- **arXiv 邮件订阅**：只能按类别订阅，无法精准筛选（信噪比低）
- **Google Scholar alerts**：基于关键词匹配，容易漏报（如"Attention Is All You Need"不包含"transformer"关键词）
- **Papers with Code**：无个性化推荐，需要主动浏览

**核心痛点**：
- 关键词筛选是"字符串匹配"（浅层），无法理解问题域（深层）
- 无法实现"零漏报"（同义表述会被遗漏）
- 筛选后仍需花时间阅读英文摘要

### 目标

提供一个基于研究母题（Research Topics）的 arXiv 论文自动筛选和摘要工具，实现：
- **零漏报**：LLM 理解问题域，找到所有相关论文（即使用词不同）
- **80% 降噪**：从 100 篇降到 20 篇高相关论文
- **中文摘要**：快速理解核心贡献，节省阅读时间

### MVP 范围

- ✅ 爬取指定类别的 arXiv 论文（如 cs.CV, cs.AI）
- ✅ 基于研究母题的 LLM 筛选
- ✅ 为通过筛选的论文生成中文摘要
- ✅ 输出 Markdown 格式（适合导入 Obsidian）
- ❌ Web UI（保留到二期）
- ❌ 邮件推送（保留到二期）
- ❌ 并发处理（保留到二期）

---

## 需求

### 需求1：arXiv 论文爬取 ✅ **[MVP 范围]**

**用户故事：** 作为科研人员，我希望能自动爬取 arXiv 指定类别的最新论文，以便不错过重要进展。

#### 验收标准

1. ✅ WHEN 用户配置类别（如 cs.CV, cs.AI）THEN 系统 SHALL 从 arXiv RSS 获取这些类别的论文
2. ✅ WHEN 单个类别论文数 > 50 THEN 系统 SHALL 只爬取最新的 50 篇（可配置）
3. ✅ WHEN arXiv API 失败 THEN 系统 SHALL 显示清晰的错误提示
4. ✅ 爬取的论文 SHALL 包含：标题、摘要、作者、arXiv ID、链接、发布日期、类别标签
5. ✅ 爬取时间 SHALL < 1 分钟（100 篇论文）

---

### 需求2：母题驱动筛选 ✅ **[MVP 范围 - 核心功能]**

**用户故事：** 作为科研人员，我希望根据我关心的研究母题自动筛选论文，而不是手动浏览所有论文。

#### 验收标准

1. ✅ WHEN 用户定义研究母题（如"AI Agent 的工具调用优化"）THEN 系统 SHALL 使用 LLM 判断每篇论文是否匹配
2. ✅ LLM 判断 SHALL 基于语义理解，不是简单的关键词匹配
   - 示例：母题"长视频理解的效率问题"能匹配"Efficient Video Transformers"（即使标题中没有"长视频"）
3. ✅ WHEN 论文匹配任一母题 THEN 系统 SHALL 保留该论文并记录匹配原因
4. ✅ WHEN 论文不匹配任何母题 THEN 系统 SHALL 丢弃该论文
5. ✅ 筛选准确率 SHALL > 80%（手动验证 20 篇）
6. ✅ 筛选时间 SHALL < 2 分钟（100 篇论文）

#### Prompt 设计要求

```
论文标题：{title}
论文摘要：{abstract}

用户研究母题：
1. AI Agent 的工具调用优化
2. 长视频理解的效率问题
3. RAG 中的知识图谱应用

判断：这篇论文是否直接解决上述任一母题？
要求：
- 只回答"是"或"否"
- 如果是，说明匹配的母题编号和简短原因（20字内）
- 如果论文只是略微相关，也应回答"否"

输出格式：
是/否
匹配母题：[编号]
原因：[简短说明]
```

---

### 需求3：AI 摘要生成 ✅ **[MVP 范围]**

**用户故事：** 作为科研人员，我希望快速理解论文的核心贡献，而不是阅读冗长的英文摘要。

#### 验收标准

1. ✅ WHEN 论文通过母题筛选 THEN 系统 SHALL 生成 100 字的中文摘要
2. ✅ 摘要 SHALL 包含：
   - 核心贡献（这篇论文解决了什么问题？）
   - 技术方法（用了什么方法？）
   - 与研究母题的关联（为什么匹配你的母题？）
3. ✅ 摘要质量：普通人能在 30 秒内理解论文核心
4. ✅ 摘要生成时间 SHALL < 2 分钟（20 篇论文）

#### Prompt 设计要求

```
论文标题：{title}
论文摘要：{abstract}
匹配的研究母题：{matched_topic}

请生成一段 100 字的中文摘要，包含：
1. 核心贡献（这篇论文解决了什么问题？）
2. 技术方法（用了什么方法？）
3. 与研究母题的关联（为什么匹配"{matched_topic}"这个母题？）

要求：
- 语言简洁、通俗易懂
- 避免专业术语堆砌
- 突出亮点和创新点
```

---

### 需求4：Markdown 输出 ✅ **[MVP 范围]**

**用户故事：** 作为科研人员，我希望筛选结果能导入到 Obsidian 知识库，方便管理和检索。

#### 验收标准

1. ✅ WHEN 处理完成 THEN 系统 SHALL 生成 Markdown 文件：`output/YYYY-MM-DD.md`
2. ✅ 文件格式 SHALL 包含：
   - 统计信息（爬取数、筛选数、成本）
   - 论文列表（标题、作者、匹配母题、摘要、arXiv 链接）
3. ✅ 文件 SHALL 适合导入 Obsidian（支持 Wikilink 和标签）
4. ✅ 历史文件 SHALL 保留在 `output/archive/` 目录

#### 输出格式示例

```markdown
# arXiv 每日精选 - 2024-01-15

## 📊 统计信息

- **爬取论文**：127 篇
- **筛选后**：23 篇（筛选率：18.1%）
- **成本**：¥0.09
- **运行时间**：4 分 32 秒

---

## 📄 论文列表

### 1. [Attention Is All You Need](https://arxiv.org/abs/1706.03762)

**作者**：Ashish Vaswani, Noam Shazeer, Niki Parmar, et al.

**匹配母题**：注意力机制的新架构

**摘要**：
本文提出了 Transformer 架构，完全基于注意力机制，抛弃了传统的 RNN 和 CNN。核心贡献是证明了纯注意力机制足以实现序列建模，且训练效率更高。技术方法包括多头自注意力和位置编码。这篇论文直接回答了"如何设计更高效的注意力架构"这一母题，是该领域的奠基性工作。

**arXiv**：[1706.03762](https://arxiv.org/abs/1706.03762)
**发布日期**：2017-06-12

---

### 2. [BERT: Pre-training of Deep Bidirectional Transformers](https://arxiv.org/abs/1810.04805)

...
```

---

### 需求5：配置管理 ✅ **[MVP 范围]**

**用户故事：** 作为用户，我希望能简单配置研究母题和 API 密钥，无需修改代码。

#### 验收标准

1. ✅ WHEN 用户创建 `.env` 文件 THEN 系统 SHALL 读取 API 密钥和 Base URL
2. ✅ WHEN 用户编辑 `config/research_topics.txt` THEN 系统 SHALL 读取研究母题列表
3. ✅ 配置文件 SHALL 支持注释（`#` 开头的行被忽略）
4. ✅ WHEN 配置文件缺失或格式错误 THEN 系统 SHALL 显示清晰的错误提示

#### 配置文件格式

**.env**：
```bash
OPENAI_API_KEY=sk-xxxxxxxx
OPENAI_BASE_URL=https://api.deepseek.com
MODEL_NAME=deepseek-chat
ARXIV_CATEGORIES=cs.CV,cs.CL,cs.AI,cs.LG
```

**research_topics.txt**：
```
# 我的研究母题（每行一个）
AI Agent 的工具调用优化
长视频理解的效率问题
RAG 中的知识图谱应用

# 可解释性方向
Sparse Autoencoder 在可解释性中的应用
```

---

### 需求6：错误处理 ✅ **[MVP 范围]**

**用户故事：** 作为用户，我希望在出错时能看到清晰的错误提示，而不是神秘的技术堆栈。

#### 验收标准

1. ✅ WHEN API 密钥无效 THEN 系统 SHALL 提示"API 密钥无效，请检查 .env 文件"
2. ✅ WHEN 网络连接失败 THEN 系统 SHALL 提示"无法连接到 arXiv/OpenAI，请检查网络"
3. ✅ WHEN LLM 调用超时 THEN 系统 SHALL 重试 3 次后提示"LLM 调用超时，请稍后重试"
4. ✅ WHEN 论文解析失败 THEN 系统 SHALL 跳过该论文并记录到日志
5. ✅ 错误提示 SHALL 用户友好（非技术用语）

---

## 技术约束

1. **零依赖库**：不引入复杂框架（如 LangChain、LlamaIndex）
2. **极简代码**：核心逻辑 < 300 行（不含注释）
3. **低成本**：每日运行成本 < ¥0.10（使用 DeepSeek API）
4. **快速运行**：完整流程 < 5 分钟（100 篇论文）

---

## 非功能需求

### 1. 性能

- 爬取 100 篇论文：< 1 分钟
- 筛选 100 篇论文：< 2 分钟（LLM 调用）
- 生成 20 篇摘要：< 2 分钟（LLM 调用）
- 总运行时间：< 5 分钟

### 2. 用户体验

- 配置简单：只需编辑 2 个文件（`.env` 和 `research_topics.txt`）
- 错误提示清晰：非技术用语，指向具体的解决方案
- 输出格式友好：适合导入 Obsidian

### 3. 可维护性

- 代码模块化：fetcher、filter、summarizer、formatter 独立
- 数据结构清晰：Paper、FilteredPaper、SummarizedPaper
- 文档同步：需求、设计、代码保持一致

### 4. 成本控制

- 每日运行成本 < ¥0.10
- 统计 token 消耗并显示在输出中
- 支持设置每日最大成本（超过后停止处理）

---

## 未来扩展（非 MVP 范围）

### 二期功能

1. **Web UI**：
   - 网页配置界面（无需编辑配置文件）
   - 实时查看处理进度
   - 历史记录浏览

2. **邮件推送**：
   - 每日摘要发送到邮箱
   - 支持自定义推送时间

3. **历史追踪**：
   - 论文被引量监控
   - 代码实现追踪（GitHub stars）

4. **知识图谱**：
   - 自动挂载到 Obsidian 概念网络
   - 生成论文之间的关联关系

5. **GitHub Actions**：
   - 自动化每日运行
   - 结果推送到 GitHub Pages

### 扩展原则

- ❌ **不要**：一次性加所有功能（过度设计）
- ✅ **要**：先验证核心价值（母题筛选是否有效）
- ✅ **要**：每次只加一个功能，确保向后兼容

---

## 验收检查清单

### ✅ 功能完整性

- [ ] 能成功爬取指定类别的 arXiv 论文（至少 50 篇）
- [ ] 母题筛选的准确率 > 80%（手动验证 20 篇）
- [ ] 摘要质量：普通人能在 30 秒内理解论文核心贡献
- [ ] 输出格式：Markdown，适合导入 Obsidian
- [ ] 统计信息准确：爬取数、筛选数、成本

### ✅ 用户体验

- [ ] 运行时间 < 5 分钟（100 篇论文）
- [ ] 配置简单：只需修改 `research_topics.txt` 和 `.env`
- [ ] 错误提示清晰：API 失败、网络错误等
- [ ] 输出文件命名规范：`output/YYYY-MM-DD.md`

### ✅ 代码质量

- [ ] 核心逻辑 < 300 行（不含注释）
- [ ] 没有超过 3 层的嵌套
- [ ] 关键函数有单元测试（至少覆盖 filter 和 summarizer）
- [ ] 代码符合 PEP 8 规范（使用 black 格式化）

### ✅ 成本控制

- [ ] 每日运行成本 < ¥0.10
- [ ] 输出中显示详细的 token 消耗统计
- [ ] 支持设置成本上限（可选）

---

## 测试场景

### 场景1：正常运行

**前提条件**：
- `.env` 配置正确
- `research_topics.txt` 包含 5 个母题
- arXiv API 正常

**操作步骤**：
1. 运行 `python main.py`
2. 等待处理完成

**预期结果**：
- 成功爬取 100+ 篇论文
- 筛选后剩余 15-25 篇
- 生成 `output/2024-01-15.md` 文件
- 显示成本统计：约 ¥0.05-0.10

---

### 场景2：API 密钥无效

**前提条件**：
- `.env` 中的 API 密钥错误

**操作步骤**：
1. 运行 `python main.py`

**预期结果**：
- 显示错误提示："API 密钥无效，请检查 .env 文件中的 OPENAI_API_KEY"
- 程序退出，不继续执行

---

### 场景3：研究母题为空

**前提条件**：
- `research_topics.txt` 为空或只包含注释

**操作步骤**：
1. 运行 `python main.py`

**预期结果**：
- 显示警告："未找到研究母题，请在 config/research_topics.txt 中添加至少一个母题"
- 程序退出

---

### 场景4：网络连接失败

**前提条件**：
- 断开网络连接

**操作步骤**：
1. 运行 `python main.py`

**预期结果**：
- 显示错误提示："无法连接到 arXiv，请检查网络连接"
- 程序退出

---

## 概念来源

**"研究母题"** 的定义：
- 母题（Research Topic）是一个具体的、领域相关的研究问题
- 不是宽泛的领域名称（如"深度学习"），而是具体的问题（如"长视频理解的效率问题"）
- LLM 能够理解母题的语义，找到所有相关论文（即使用词不同）

**核心思想**：
> 从"关键词筛选"升级为"问题域筛选"，让 AI 理解你关心的**母题**而非**字符串**，实现**零漏报 + 80% 降噪**。

---

## 相关文档

- **[design.md](design.md)**：设计文档（数据结构、算法实现）
- **[../CLAUDE.md](../CLAUDE.md)**：项目总览（给 AI 和开发者看）
- **[../README.md](../README.md)**：用户使用指南
