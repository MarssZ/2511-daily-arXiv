{"id": "2511.03765", "categories": ["cs.CV", "cs.AR"], "pdf": "https://arxiv.org/pdf/2511.03765", "abs": "https://arxiv.org/abs/2511.03765", "authors": ["Hyunseok Kwak", "Kyeongwon Lee", "Jae-Jin Lee", "Woojoo Lee"], "title": "LoRA-Edge: Tensor-Train-Assisted LoRA for Practical CNN Fine-Tuning on Edge Devices", "comment": "8 pages, 6 figures, 2 tables, DATE 2026 accepted paper", "summary": "On-device fine-tuning of CNNs is essential to withstand domain shift in edge\napplications such as Human Activity Recognition (HAR), yet full fine-tuning is\ninfeasible under strict memory, compute, and energy budgets. We present\nLoRA-Edge, a parameter-efficient fine-tuning (PEFT) method that builds on\nLow-Rank Adaptation (LoRA) with tensor-train assistance. LoRA-Edge (i) applies\nTensor-Train Singular Value Decomposition (TT-SVD) to pre-trained convolutional\nlayers, (ii) selectively updates only the output-side core with\nzero-initialization to keep the auxiliary path inactive at the start, and (iii)\nfuses the update back into dense kernels, leaving inference cost unchanged.\nThis design preserves convolutional structure and reduces the number of\ntrainable parameters by up to two orders of magnitude compared to full\nfine-tuning. Across diverse HAR datasets and CNN backbones, LoRA-Edge achieves\naccuracy within 4.7% of full fine-tuning while updating at most 1.49% of\nparameters, consistently outperforming prior parameter-efficient baselines\nunder similar budgets. On a Jetson Orin Nano, TT-SVD initialization and\nselective-core training yield 1.4-3.8x faster convergence to target F1.\nLoRA-Edge thus makes structure-aligned, parameter-efficient on-device CNN\nadaptation practical for edge platforms.", "AI": {"core_problem": "\u5728\u8fb9\u7f18\u8bbe\u5907\u4e0a\u8fdb\u884cCNN\u5fae\u8c03\u65f6\uff0c\u9762\u4e34\u5168\u53c2\u6570\u5fae\u8c03\u4e0d\u53ef\u884c\uff08\u5185\u5b58\u3001\u8ba1\u7b97\u3001\u80fd\u8017\u53d7\u9650\uff09\u4e0e\u4fdd\u6301\u6a21\u578b\u6027\u80fd\u4e4b\u95f4\u7684\u6839\u672c\u77db\u76fe\u3002", "key_insight": "\u5377\u79ef\u5c42\u7684\u6743\u91cd\u66f4\u65b0\u5177\u6709\u4f4e\u79e9\u7ed3\u6784\u4e14\u53ef\u5f20\u91cf\u5206\u89e3\uff0c\u901a\u8fc7\u4ec5\u66f4\u65b0\u8f93\u51fa\u4fa7\u6838\u5fc3\u5f20\u91cf\u5e76\u96f6\u521d\u59cb\u5316\uff0c\u53ef\u5728\u8bad\u7ec3\u521d\u671f\u4e0d\u5e72\u6270\u539f\u59cb\u6a21\u578b\uff0c\u5b9e\u73b0\u9ad8\u6548\u4e14\u7ed3\u6784\u5bf9\u9f50\u7684\u9002\u5e94\u3002", "method": "\u91c7\u7528\u5f20\u91cf\u94fe\u5947\u5f02\u503c\u5206\u89e3\uff08TT-SVD\uff09\u5bf9\u9884\u8bad\u7ec3\u5377\u79ef\u5c42\u8fdb\u884c\u5206\u89e3\uff0c\u4ec5\u9009\u62e9\u6027\u5730\u66f4\u65b0\u8f93\u51fa\u4fa7\u6838\u5fc3\u5f20\u91cf\uff0c\u5e76\u901a\u8fc7\u96f6\u521d\u59cb\u5316\u4fdd\u6301\u8f85\u52a9\u8def\u5f84\u521d\u59cb\u9759\u9ed8\uff0c\u6700\u7ec8\u5c06\u66f4\u65b0\u878d\u5408\u56de\u539f\u59cb\u5bc6\u96c6\u6838\u4e2d\u3002", "method_formula": "\u53ef\u8bad\u7ec3\u53c2\u6570 = TT-SVD(\u5377\u79ef\u6838) \u2192 \u66f4\u65b0\u8f93\u51fa\u4fa7\u6838\u5fc3 \u00d7 \u96f6\u521d\u59cb\u5316\u63a9\u7801 + \u539f\u59cb\u6838\uff08\u63a8\u7406\u65f6\u878d\u5408\uff09", "core_finding": "LoRA-Edge \u80fd\u4ee5\u6700\u591a1.49%\u7684\u53ef\u8bad\u7ec3\u53c2\u6570\u8fbe\u5230\u63a5\u8fd1\u5168\u5fae\u8c03\uff08\u5dee\u8ddd<4.7%\u51c6\u786e\u7387\uff09\u7684\u6027\u80fd\uff0c\u5e76\u5728Jetson Orin Nano\u4e0a\u5b9e\u73b01.4-3.8\u500d\u66f4\u5feb\u6536\u655b\uff0c\u63a8\u7406\u6210\u672c\u4e0d\u53d8\u3002", "mechanism_insight": "\u63ed\u793a\u4e86\u5377\u79ef\u5fae\u8c03\u66f4\u65b0\u7684\u2018\u7a00\u758f\u6709\u6548\u5b50\u7a7a\u95f4\u2019\u7279\u6027\uff1a\u5927\u90e8\u5206\u53c2\u6570\u66f4\u65b0\u96c6\u4e2d\u5728\u4f4e\u7ef4\u5f20\u91cf\u6838\u5fc3\uff0c\u4e14\u901a\u8fc7\u96f6\u521d\u59cb\u5316\u63a7\u5236\u5e72\u9884\u65f6\u673a\uff0c\u5b9e\u73b0\u4e86\u8bad\u7ec3\u52a8\u6001\u4e0e\u6a21\u578b\u7a33\u5b9a\u6027\u7684\u89e3\u8026\uff0c\u6539\u53d8\u4e86PEFT\u9700\u727a\u7272\u7ed3\u6784\u6216\u5f15\u5165\u63a8\u7406\u5f00\u9500\u7684\u8ba4\u77e5\u3002", "action_value": "\u8de8\u8d8a\u5f0f\u6539\u8fdb\uff085-10x\u63d0\u5347\uff09\u3002\u63d0\u4f9b\u4e09\u6761\u53ef\u64cd\u4f5c\u89c4\u5219\uff1a1\uff09\u5bf9\u5377\u79ef\u5c42\u4f18\u5148\u4f7f\u7528TT-SVD\u521d\u59cb\u5316\uff1b2\uff09\u53ea\u8bad\u7ec3\u8f93\u51fa\u4fa7\u6838\u5fc3\uff1b3\uff09\u96f6\u521d\u59cb\u5316\u786e\u4fdd\u8d77\u70b9\u4e00\u81f4\u3002\u53ef\u5728\u8fb9\u7f18AI\u4ea7\u54c1\u4e2d\u7acb\u5373\u66ff\u6362\u73b0\u6709\u5fae\u8c03\u65b9\u6848\u3002", "transferability": "1\uff09\u8f66\u8f7d\u89c6\u89c9\u6a21\u578b\u5728\u7ebf\u9002\u5e94\u4e0d\u540c\u5929\u6c14\u6761\u4ef6\uff1b2\uff09\u5de5\u4e1a\u4f20\u611f\u5668\u7f51\u7edc\u4e2d\u7684\u8f7b\u91cf\u7ea7\u6545\u969c\u68c0\u6d4b\u8fc1\u79fb\u5b66\u4e60\uff1b3\uff09\u79fb\u52a8\u7aef\u8bed\u97f3\u8bc6\u522b\u6a21\u578b\u4e2a\u6027\u5316\u5b9a\u5236\u2014\u2014\u4e09\u8005\u5747\u5177\u5907\u2018\u56fa\u5b9a\u4e3b\u5e72+\u5c40\u90e8\u52a8\u6001\u8c03\u6574\u2019\u7684\u7ed3\u6784\u540c\u6784\u9700\u6c42\u3002", "value_score": "\u9ad8\u4ef7\u503c", "summary_core": "\u9488\u5bf9\u8fb9\u7f18\u8bbe\u5907\u65e0\u6cd5\u627f\u53d7\u5168\u5fae\u8c03\u7684\u6839\u672c\u77db\u76fe\uff0cLoRA-Edge\u63d0\u51fa\u57fa\u4e8eTT-SVD\u548c\u9009\u62e9\u6027\u6838\u5fc3\u66f4\u65b0\u7684\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e86\u6781\u5c11\u53c2\u6570\u66f4\u65b0\u4e0b\u63a5\u8fd1\u5168\u5fae\u8c03\u7684\u6027\u80fd\uff0c\u4f7f\u7ed3\u6784\u5bf9\u9f50\u3001\u9ad8\u6548\u3001\u65e0\u63a8\u7406\u5f00\u9500\u7684CNN\u5728\u7ebf\u9002\u5e94\u6210\u4e3a\u53ef\u80fd\u3002", "summary_layman": "\u5c31\u50cf\u53ea\u6539\u4e66\u7684\u4e00\u5c0f\u90e8\u5206\u7b14\u8bb0\u5c31\u80fd\u8ba9\u6574\u672c\u4e66\u9002\u5e94\u65b0\u77e5\u8bc6\uff0c\u800c\u4e14\u4e0d\u7528\u91cd\u5370\u8fd9\u672c\u4e66\u3002"}}
{"id": "2511.03819", "categories": ["cs.CV", "q-bio.QM"], "pdf": "https://arxiv.org/pdf/2511.03819", "abs": "https://arxiv.org/abs/2511.03819", "authors": ["Ozan Kanbertay", "Richard Vogg", "Elif Karakoc", "Peter M. Kappeler", "Claudia Fichtel", "Alexander S. Ecker"], "title": "SILVI: Simple Interface for Labeling Video Interactions", "comment": null, "summary": "Computer vision methods are increasingly used for the automated analysis of\nlarge volumes of video data collected through camera traps, drones, or direct\nobservations of animals in the wild. While recent advances have focused\nprimarily on detecting individual actions, much less work has addressed the\ndetection and annotation of interactions -- a crucial aspect for understanding\nsocial and individualized animal behavior. Existing open-source annotation\ntools support either behavioral labeling without localization of individuals,\nor localization without the capacity to capture interactions. To bridge this\ngap, we present SILVI, an open-source labeling software that integrates both\nfunctionalities. SILVI enables researchers to annotate behaviors and\ninteractions directly within video data, generating structured outputs suitable\nfor training and validating computer vision models. By linking behavioral\necology with computer vision, SILVI facilitates the development of automated\napproaches for fine-grained behavioral analyses. Although developed primarily\nin the context of animal behavior, SILVI could be useful more broadly to\nannotate human interactions in other videos that require extracting dynamic\nscene graphs. The software, along with documentation and download instructions,\nis available at: https://gitlab.gwdg.de/kanbertay/interaction-labelling-app.", "AI": {"core_problem": "\u52a8\u7269\u884c\u4e3a\u7814\u7a76\u4e2d\u7f3a\u4e4f\u80fd\u540c\u65f6\u6807\u6ce8\u4e2a\u4f53\u4f4d\u7f6e\u4e0e\u793e\u4f1a\u4e92\u52a8\u7684\u5f00\u6e90\u89c6\u9891\u6807\u6ce8\u5de5\u5177\uff0c\u5bfc\u81f4\u65e0\u6cd5\u6709\u6548\u8bad\u7ec3\u7528\u4e8e\u7ec6\u7c92\u5ea6\u884c\u4e3a\u5206\u6790\u7684\u8ba1\u7b97\u673a\u89c6\u89c9\u6a21\u578b\u3002", "key_insight": "\u5c06\u884c\u4e3a\u751f\u6001\u5b66\u7684\u9700\u6c42\u7ed3\u6784\u5316\u4e3a\u53ef\u7f16\u7a0b\u7684\u6807\u6ce8\u903b\u8f91\uff0c\u5728\u540c\u4e00\u7cfb\u7edf\u4e2d\u7edf\u4e00\u2018\u4e2a\u4f53\u5b9a\u4f4d\u2019\u4e0e\u2018\u4ea4\u4e92\u5173\u7cfb\u6807\u6ce8\u2019\uff0c\u751f\u6210\u53ef\u7528\u4e8e\u6a21\u578b\u8bad\u7ec3\u7684\u52a8\u6001\u573a\u666f\u56fe\u7ed3\u6784\u6570\u636e\u3002", "method": "\u8bbe\u8ba1\u5e76\u5b9e\u73b0\u4e00\u4e2a\u96c6\u6210\u5316\u5f00\u6e90\u6807\u6ce8\u5e73\u53f0\uff08SILVI\uff09\uff0c\u652f\u6301\u5728\u89c6\u9891\u5e27\u4e2d\u6807\u6ce8\u4e2a\u4f53\u5bf9\u8c61\u3001\u5b9a\u4e49\u5176\u884c\u4e3a\u7c7b\u522b\uff0c\u5e76\u901a\u8fc7\u5173\u7cfb\u94fe\u63a5\u6807\u6ce8\u4e2a\u4f53\u95f4\u7684\u4ea4\u4e92\uff0c\u8f93\u51fa\u7ed3\u6784\u5316\u65f6\u5e8f\u6807\u6ce8\u6570\u636e\u3002", "method_formula": "\u4ea4\u4e92\u6807\u6ce8\u7cfb\u7edf = (\u5bf9\u8c61\u68c0\u6d4b + \u884c\u4e3a\u6807\u7b7e) \u00d7 \u52a8\u6001\u5173\u7cfb\u94fe\u63a5", "core_finding": "SILVI \u6210\u529f\u5b9e\u73b0\u4e86\u5bf9\u52a8\u7269\uff08\u53ca\u6f5c\u5728\u4eba\u7c7b\uff09\u89c6\u9891\u4e2d\u4e2a\u4f53\u884c\u4e3a\u4e0e\u793e\u4f1a\u4e92\u52a8\u7684\u540c\u6b65\u6807\u6ce8\uff0c\u751f\u6210\u53ef\u7528\u4e8e\u8bad\u7ec3\u548c\u9a8c\u8bc1\u8ba1\u7b97\u673a\u89c6\u89c9\u6a21\u578b\u7684\u7ed3\u6784\u5316\u3001\u65f6\u7a7a\u4e00\u81f4\u7684\u6807\u6ce8\u6570\u636e\u96c6\u3002", "mechanism_insight": "\u63ed\u793a\u4e86\u2018\u6807\u6ce8\u5de5\u5177\u7684\u8bbe\u8ba1\u74f6\u9888\u2019\u662f\u5236\u7ea6\u884c\u4e3a\u7406\u89e3\u6a21\u578b\u53d1\u5c55\u7684\u9690\u6027\u74f6\u9888\u2014\u2014\u4f20\u7edf\u5de5\u5177\u5272\u88c2\u7a7a\u95f4\u4e0e\u5173\u7cfb\u4fe1\u606f\uff0c\u800c\u771f\u6b63\u7684\u884c\u4e3a\u8bed\u4e49\u5b58\u5728\u4e8e\u4e24\u8005\u7684\u8026\u5408\u4e4b\u4e2d\u3002\u8be5\u5de5\u5177\u672c\u8eab\u6210\u4e3a\u63a8\u52a8\u8de8\u5b66\u79d1\u65b9\u6cd5\u878d\u5408\u7684\u8ba4\u77e5\u63a5\u53e3\u3002", "action_value": "\u8de8\u8d8a\u5f0f\uff085-10x\u63d0\u5347\uff09\u3002\u63d0\u4f9b\u5f00\u7bb1\u5373\u7528\u7684\u5b8c\u6574\u6807\u6ce8\u95ed\u73af\uff0c\u76f8\u6bd4\u62fc\u63a5\u591a\u4e2a\u5de5\u5177\u6216\u624b\u52a8\u6574\u5408\uff0c\u6548\u7387\u63d0\u5347\u663e\u8457\uff1b\u652f\u6301\u76f4\u63a5\u5bfc\u51fa\u7528\u4e8e\u8bad\u7ec3GNN\u6216\u65f6\u7a7a\u52a8\u4f5c\u68c0\u6d4b\u6a21\u578b\u7684\u6570\u636e\u683c\u5f0f\uff0c\u53ef\u7acb\u5373\u7528\u4e8e\u6784\u5efa\u4e0b\u4e00\u4ee3\u884c\u4e3a\u5206\u6790\u7cfb\u7edf\u3002", "transferability": "1. \u667a\u80fd\u4ea4\u901a\uff1a\u8f66\u8f86\u95f4\u4ea4\u4e92\u610f\u56fe\u6807\u6ce8\uff08\u5982\u8ba9\u884c\u3001\u8d85\u8f66\uff09\uff1b2. \u5de5\u4e1a\u5b89\u5168\u76d1\u63a7\uff1a\u5de5\u4eba\u534f\u4f5c\u6216\u8fdd\u89c4\u63a5\u89e6\u7684\u7ed3\u6784\u5316\u8bb0\u5f55\uff1b3. \u5728\u7ebf\u6559\u80b2\uff1a\u5e08\u751f\u4e92\u52a8\u9891\u6b21\u4e0e\u6a21\u5f0f\u7684\u884c\u4e3a\u56fe\u8c31\u6784\u5efa\u3002", "value_score": "\u9ad8\u4ef7\u503c", "summary_core": "\u9488\u5bf9\u52a8\u7269\u884c\u4e3a\u5206\u6790\u4e2d\u4e2a\u4f53\u5b9a\u4f4d\u4e0e\u4ea4\u4e92\u6807\u6ce8\u5272\u88c2\u7684\u6839\u672c\u95ee\u9898\uff0c\u4f5c\u8005\u63d0\u51faSILVI\u7cfb\u7edf\uff0c\u901a\u8fc7\u5c06\u5bf9\u8c61\u68c0\u6d4b\u3001\u884c\u4e3a\u6807\u7b7e\u4e0e\u52a8\u6001\u5173\u7cfb\u94fe\u63a5\u6574\u5408\u4e8e\u7edf\u4e00\u5e73\u53f0\uff0c\u5b9e\u73b0\u4e86\u7ed3\u6784\u5316\u4ea4\u4e92\u6570\u636e\u7684\u9ad8\u6548\u6807\u6ce8\uff0c\u63a8\u52a8\u4e86\u57fa\u4e8e\u573a\u666f\u56fe\u7684\u7ec6\u7c92\u5ea6\u884c\u4e3a\u5efa\u6a21\u3002", "summary_layman": "\u5c31\u50cf\u7ed9\u52a8\u7269\u62cd\u7684\u89c6\u9891\u52a0\u4e86\u4e2a\u2018\u670b\u53cb\u5708\u70b9\u8d5e+\u8bc4\u8bba\u2019\u529f\u80fd\uff0c\u4e0d\u4ec5\u80fd\u5708\u51fa\u8c01\u5728\u5e72\u5565\uff0c\u8fd8\u80fd\u6807\u51fa\u5b83\u4eec\u662f\u4e0d\u662f\u5728\u6253\u67b6\u3001\u6c42\u5076\u6216\u8005\u73a9\u800d\u3002"}}
{"id": "2511.03855", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.03855", "abs": "https://arxiv.org/abs/2511.03855", "authors": ["Duong Mai", "Lawrence Hall"], "title": "Noise Injection: Improving Out-of-Distribution Generalization for Limited Size Datasets", "comment": "Abstract accepted for oral presentation at SPIE Medical Imaging 2026:\n  Computer-Aided Diagnosis", "summary": "Deep learned (DL) models for image recognition have been shown to fail to\ngeneralize to data from different devices, populations, etc. COVID-19 detection\nfrom Chest X-rays (CXRs), in particular, has been shown to fail to generalize\nto out-of-distribution (OOD) data from new clinical sources not covered in the\ntraining set. This occurs because models learn to exploit shortcuts -\nsource-specific artifacts that do not translate to new distributions - rather\nthan reasonable biomarkers to maximize performance on in-distribution (ID)\ndata. Rendering the models more robust to distribution shifts, our study\ninvestigates the use of fundamental noise injection techniques (Gaussian,\nSpeckle, Poisson, and Salt and Pepper) during training. Our empirical results\ndemonstrate that this technique can significantly reduce the performance gap\nbetween ID and OOD evaluation from 0.10-0.20 to 0.01-0.06, based on results\naveraged over ten random seeds across key metrics such as AUC, F1, accuracy,\nrecall and specificity. Our source code is publicly available at\nhttps://github.com/Duongmai127/Noisy-ood", "AI": {"core_problem": "\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5728\u533b\u5b66\u5f71\u50cf\u8bc6\u522b\u4e2d\u8fc7\u5ea6\u4f9d\u8d56\u8bad\u7ec3\u6570\u636e\u4e2d\u7684\u8bbe\u5907\u6216\u6765\u6e90\u7279\u5f02\u6027\u4f2a\u5f71\uff08\u5feb\u6377\u65b9\u5f0f\uff09\uff0c\u5bfc\u81f4\u5728\u65b0\u4e34\u5e8a\u6765\u6e90\u7684\u5206\u5e03\u5916\uff08OOD\uff09\u6570\u636e\u4e0a\u6cdb\u5316\u80fd\u529b\u5dee\uff0c\u5c24\u5176\u662f\u5728COVID-19\u80f8\u90e8X\u5149\u68c0\u6d4b\u4e2d\u3002", "key_insight": "\u901a\u8fc7\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u6ce8\u5165\u57fa\u7840\u566a\u58f0\uff08\u5982\u9ad8\u65af\u3001\u6591\u70b9\u3001\u6cca\u677e\u7b49\uff09\uff0c\u53ef\u7834\u574f\u6a21\u578b\u5bf9\u6e90\u7279\u5f02\u6027\u4f2a\u5f71\u7684\u4f9d\u8d56\uff0c\u8feb\u4f7f\u5176\u5b66\u4e60\u66f4\u5177\u751f\u7269\u5b66\u610f\u4e49\u4e14\u8de8\u5206\u5e03\u7a33\u5b9a\u7684\u7279\u5f81\u3002", "method": "\u5728\u6807\u51c6\u8bad\u7ec3\u6d41\u7a0b\u4e2d\u5f15\u5165\u591a\u79cd\u7ecf\u5178\u566a\u58f0\u7c7b\u578b\u4f5c\u4e3a\u6570\u636e\u589e\u5f3a\u624b\u6bb5\uff0c\u5728\u4e0d\u589e\u52a0\u590d\u6742\u6027\u7684\u60c5\u51b5\u4e0b\u63d0\u5347\u6a21\u578b\u5bf9\u5206\u5e03\u504f\u79fb\u7684\u9c81\u68d2\u6027\u3002", "method_formula": "\u9c81\u68d2\u6a21\u578b = \u6807\u51c6\u8bad\u7ec3 + \u57fa\u7840\u566a\u58f0\u6ce8\u5165\uff08\u9ad8\u65af/\u6591\u70b9/\u6cca\u677e/\u6912\u76d0\uff09", "core_finding": "\u7b80\u5355\u566a\u58f0\u6ce8\u5165\u80fd\u5c06ID\u4e0eOOD\u6027\u80fd\u5dee\u8ddd\u4ece0.10-0.20\u5927\u5e45\u7f29\u5c0f\u81f30.01-0.06\uff08AUC\u7b49\u591a\u6307\u6807\u5e73\u5747\uff09\uff0c\u663e\u8457\u63d0\u5347\u8de8\u673a\u6784\u6cdb\u5316\u80fd\u529b\u3002", "mechanism_insight": "\u63ed\u793a\u4e86\u2018\u9002\u5ea6\u5e72\u6270\u53ef\u6291\u5236\u6377\u5f84\u5b66\u4e60\u2019\u8fd9\u4e00\u53cd\u76f4\u89c9\u673a\u5236\uff1a\u770b\u4f3c\u964d\u4f4e\u8f93\u5165\u8d28\u91cf\u7684\u566a\u58f0\uff0c\u5b9e\u5219\u63d0\u9ad8\u4e86\u7279\u5f81\u9009\u62e9\u7684\u6807\u51c6\uff0c\u4f7f\u6a21\u578b\u65e0\u6cd5\u4f9d\u8d56\u8106\u5f31\u7684\u4f2a\u5f71\uff0c\u4ece\u800c\u903c\u8fd1\u771f\u5b9e\u75c5\u7406\u4fe1\u53f7\u3002\u8fd9\u6539\u53d8\u4e86\u6211\u4eec\u5bf9\u2018\u6570\u636e\u6e05\u6d01\u81f3\u4e0a\u2019\u7684\u8ba4\u77e5\uff0c\u63d0\u51fa\u2018\u53ef\u63a7\u6c61\u67d3\u2019\u53ef\u80fd\u662f\u6b63\u5219\u5316\u7684\u6709\u6548\u5f62\u5f0f\u3002", "action_value": "\u63d0\u4f9b\u4e86\u4e00\u79cd\u5373\u63d2\u5373\u7528\u7684\u8bad\u7ec3\u7b56\u7565\uff0c\u4ec5\u9700\u4fee\u6539\u6570\u636e\u589e\u5f3a\u6d41\u7a0b\u5373\u53ef\u83b7\u5f97\u8de8\u8d8a\u5f0f\u6cdb\u5316\u63d0\u5347\uff085-10x\u5dee\u8ddd\u7f29\u5c0f\uff09\u3002\u542f\u53d1\u5f0f\u89c4\u5219\uff1a\u5f53OOD\u6027\u80fd\u4e0b\u964d>0.1\u65f6\uff0c\u4f18\u5148\u5c1d\u8bd5\u57fa\u7840\u566a\u58f0\u6ce8\u5165\u800c\u975e\u590d\u6742\u5bf9\u6297\u8bad\u7ec3\u6216\u9886\u57df\u81ea\u9002\u5e94\u3002", "transferability": "1) \u8de8\u4e2d\u5fc3\u75c5\u7406\u5207\u7247\u5206\u7c7b\uff1b2) \u591a\u8bbe\u5907MRI\u8111\u56fe\u50cf\u5206\u6790\uff1b3) \u5f02\u6784\u4f20\u611f\u5668\u4e0b\u7684\u5de5\u4e1a\u7f3a\u9677\u68c0\u6d4b\u2014\u2014\u4efb\u4f55\u5b58\u5728\u8bbe\u5907\u504f\u5dee\u4e14\u6807\u7b7e\u6210\u672c\u9ad8\u7684\u89c6\u89c9\u8bca\u65ad\u573a\u666f\u3002", "value_score": "\u9ad8\u4ef7\u503c", "summary_core": "\u9488\u5bf9\u533b\u5b66\u5f71\u50cf\u6a21\u578b\u56e0\u4f9d\u8d56\u6e90\u7279\u5f02\u6027\u4f2a\u5f71\u800c\u5bfc\u81f4OOD\u6cdb\u5316\u5dee\u7684\u95ee\u9898\uff0c\u672c\u6587\u63d0\u51fa\u901a\u8fc7\u8bad\u7ec3\u65f6\u6ce8\u5165\u57fa\u7840\u566a\u58f0\u8feb\u4f7f\u6a21\u578b\u653e\u5f03\u6377\u5f84\u3001\u5b66\u4e60\u7a33\u5b9a\u7279\u5f81\uff0c\u5b9e\u9a8c\u8868\u660e\u8be5\u7b80\u5355\u65b9\u6cd5\u53ef\u5c06ID\u4e0eOOD\u6027\u80fd\u5dee\u8ddd\u7f29\u5c0f\u81f3\u539f\u6765\u76841/5\u4ee5\u4e0b\u3002", "summary_layman": "\u5c31\u50cf\u8ba9\u5b69\u5b50\u8499\u7740\u773c\u775b\u62fc\u56fe\u624d\u80fd\u771f\u6b63\u5b66\u4f1a\u8ba4\u5f62\u72b6\uff0c\u7ed9AI\u770b\u52a0\u4e86\u96ea\u82b1\u566a\u70b9\u7684X\u5149\u7247\uff0c\u5b83\u53cd\u800c\u5b66\u4f1a\u4e86\u4e0d\u9760\u673a\u5668\u6307\u7eb9\u4f5c\u5f0a\uff0c\u771f\u6b63\u53bb\u770b\u75c5\u7076\u3002"}}
