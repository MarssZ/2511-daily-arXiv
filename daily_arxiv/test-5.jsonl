{"title": "Policy Learning from Tutorial Books via Understanding, Rehearsing and Introspecting", "authors": ["Xiong-Hui Chen", "Ziyan Wang", "Yali Du", "Shengyi Jiang", "Meng Fang", "Yang Yu", "Jun Wang"], "summary": "When humans need to learn a new skill, we can acquire knowledge through written books, including textbooks, tutorials, etc. However, current research for decision-making, like reinforcement learning (RL), has primarily required numerous real interactions with the target environment to learn a skill, while failing to utilize the existing knowledge already summarized in the text. The success of Large Language Models (LLMs) sheds light on utilizing such knowledge behind the books. In this paper, we discuss a new policy learning problem called Policy Learning from tutorial Books (PLfB) upon the shoulders of LLMs’ systems, which aims to leverage rich resources such as tutorial books to derive a policy network. Inspired by how humans learn from books, we solve the problem via a three-stage framework: Understanding, Rehearsing, and Introspecting (URI). In particular, it first rehearses decision-making trajectories based on the derived knowledge after understanding the books, then introspects in the imaginary dataset to distill a policy network.  We build two benchmarks for PLfB~based on Tic-Tac-Toe and Football games. In experiment, URI's policy achieves at least 44% net win rate against GPT-based agents without any real data; In Football game, which is a complex scenario, URI's policy beat the built-in AIs with a …", "abs": "https://neurips.cc/virtual/2024/oral/97989", "categories": ["NeurIPS 2024 Oral"], "comment": null, "source": "neurips", "id": "neurips2024_oral_97989", "pdf": "https://openreview.net/pdf?id=Ddak3nSqQM"}
{"title": "MetaLA: Unified Optimal Linear Approximation to Softmax Attention Map", "authors": ["YUHONG CHOU", "Man Yao", "Kexin Wang", "Yuqi Pan", "Rui-Jie Zhu", "Jibin Wu", "Yiran Zhong", "Yu Qiao", "Bo Xu", "Guoqi Li"], "summary": "Various linear complexity models, such as Linear Transformer (LinFormer), State Space Model (SSM), and Linear RNN (LinRNN), have been proposed to replace the conventional softmax attention in Transformer structures. However, the optimal design of these linear models is still an open question. In this work, we attempt to answer this question by finding the best linear approximation to softmax attention from a theoretical perspective. We start by unifying existing linear complexity models as the linear attention form and then identify three conditions for the optimal linear attention design: (1) Dynamic memory ability; (2) Static approximation ability; (3) Least parameter approximation. We find that none of the current linear models meet all three conditions, resulting in suboptimal performance. Instead, we propose Meta Linear Attention (MetaLA) as a solution that satisfies these conditions. Our experiments on Multi-Query Associative Recall (MQAR) task, language modeling, image classification, and Long-Range Arena (LRA) benchmark demonstrate that MetaLA is more effective than the existing linear models.", "abs": "https://neurips.cc/virtual/2024/oral/97971", "categories": ["NeurIPS 2024 Oral"], "comment": null, "source": "neurips", "id": "neurips2024_oral_97971", "pdf": "https://openreview.net/pdf?id=Y8YVCOMEpz"}
{"title": "A Taxonomy of Challenges to Curating Fair Datasets", "authors": ["Dora Zhao", "Morgan Scheuerman", "Pooja Chitre", "Jerone Andrews", "Georgia Panagiotidou", "Shawn Walker", "Kathleen Pine", "Alice Xiang"], "summary": "Despite extensive efforts to create fairer machine learning (ML) datasets, there remains a limited understanding of the practical aspects of dataset curation. Drawing from interviews with 30 ML dataset curators, we present a comprehensive taxonomy of the challenges and trade-offs encountered throughout the dataset curation lifecycle. Our findings underscore overarching issues within the broader fairness landscape that impact data curation. We conclude with recommendations aimed at fostering systemic changes to better facilitate fair dataset curation practices.", "abs": "https://neurips.cc/virtual/2024/oral/98019", "categories": ["NeurIPS 2024 Oral"], "comment": null, "source": "neurips", "id": "neurips2024_oral_98019", "pdf": ""}
{"title": "ChaosBench: A Multi-Channel, Physics-Based Benchmark for Subseasonal-to-Seasonal Climate Prediction", "authors": ["Juan Nathaniel", "Yongquan Qu", "Tung Nguyen", "Sungduk Yu", "Julius Busecke", "Aditya Grover", "Pierre Gentine"], "summary": "Accurate prediction of climate in the subseasonal-to-seasonal scale is crucial for disaster preparedness and robust decision making amidst climate change. Yet, forecasting beyond the weather timescale is challenging because it deals with problems other than initial condition, including boundary interaction, butterfly effect, and our inherent lack of physical understanding. At present, existing benchmarks tend to have shorter forecasting range of up-to 15 days, do not include a wide range of operational baselines, and lack physics-based constraints for explainability. Thus, we propose ChaosBench, a challenging benchmark to extend the predictability range of data-driven weather emulators to S2S timescale. First, ChaosBench is comprised of variables beyond the typical surface-atmospheric ERA5 to also include ocean, ice, and land reanalysis products that span over 45 years to allow for full Earth system emulation that respects boundary conditions. We also propose physics-based, in addition to deterministic and probabilistic metrics, to ensure a physically-consistent ensemble that accounts for butterfly effect. Furthermore, we evaluate on a diverse set of physics-based forecasts from four national weather agencies as baselines to our data-driven counterpart such as ViT/ClimaX, PanguWeather, GraphCast, and FourCastNetV2. Overall, we find methods originally developed for weather-scale applications fail on S2S task: their performance simply collapse to …", "abs": "https://neurips.cc/virtual/2024/oral/98017", "categories": ["NeurIPS 2024 Oral"], "comment": null, "source": "neurips", "id": "neurips2024_oral_98017", "pdf": ""}
{"title": "Graph Diffusion Transformers for Multi-Conditional Molecular Generation", "authors": ["Gang Liu", "Jiaxin Xu", "Tengfei Luo", "Meng Jiang"], "summary": "Inverse molecular design with diffusion models holds great potential for advancements in material and drug discovery. Despite success in unconditional molecule generation, integrating multiple properties such as synthetic score and gas permeability as condition constraints into diffusion models remains unexplored. We present the Graph Diffusion Transformer (Graph DiT) for multi-conditional molecular generation. Graph DiT has a condition encoder to learn the representation of numerical and categorical properties and utilizes a Transformer-based graph denoiser to achieve molecular graph denoising under conditions. Unlike previous graph diffusion models that add noise separately on the atoms and bonds in the forward diffusion process, we propose a graph-dependent noise model for training Graph DiT, designed to accurately estimate graph-related noise in molecules. We extensively validate the Graph DiT for multi-conditional polymer and small molecule generation. Results demonstrate our superiority across metrics from distribution learning to condition control for molecular properties. A polymer inverse design task for gas separation with feedback from domain experts further demonstrates its practical utility. The code is available at https://github.com/liugangcode/Graph-DiT.", "abs": "https://neurips.cc/virtual/2024/oral/97964", "categories": ["NeurIPS 2024 Oral"], "comment": null, "source": "neurips", "id": "neurips2024_oral_97964", "pdf": "https://openreview.net/pdf?id=cfrDLD1wfO"}
{"title": "Bayesian-guided Label Mapping for Visual Reprogramming", "authors": ["Chengyi Cai", "Zesheng Ye", "Lei Feng", "Jianzhong Qi", "Feng Liu"], "summary": "*Visual reprogramming* (VR) leverages the intrinsic capabilities of pretrained vision models by adapting their input or output interfaces to solve downstream tasks whose labels (i.e., downstream labels) might be totally different from the labels associated with the pretrained models (i.e., pretrained labels). When adapting the output interface, label mapping methods transform the pretrained labels to downstream labels by establishing a gradient-free one-to-one correspondence between the two sets of labels.However, in this paper, we reveal that one-to-one mappings may overlook the complex relationship between pretrained and downstream labels. Motivated by this observation, we propose a ***B**ayesian-guided **L**abel **M**apping* (BLM) method. BLM constructs an iteratively-updated probabilistic label mapping matrix, with each element quantifying a pairwise relationship between pretrained and downstream labels.The assignment of values to the constructed matrix is guided by Bayesian conditional probability, considering the joint distribution of the downstream labels and the labels predicted by the pretrained model on downstream samples. Experiments conducted on both pretrained vision models (e.g., ResNeXt) and vision-language models (e.g., CLIP) demonstrate the superior performance of BLM over existing label mapping methods. The success of BLM also offers a probabilistic lens through which to understand and analyze the effectiveness of VR.Our code is available at https://github.com/tmlr-group/BayesianLM.", "abs": "https://neurips.cc/virtual/2024/oral/98002", "categories": ["NeurIPS 2024 Oral"], "comment": null, "source": "neurips", "id": "neurips2024_oral_98002", "pdf": "https://openreview.net/pdf?id=135eKqDoRR"}
