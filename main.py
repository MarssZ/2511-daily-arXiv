"""
daily-arXiv: AIé©±åŠ¨çš„è®ºæ–‡æ¯é¢˜ç­›é€‰å™¨

ä¸»ç¨‹åºå…¥å£
"""

import time
from datetime import datetime
from pathlib import Path

# TODO: å®ç°å®Œæ•´çš„å¯¼å…¥
# from openai import OpenAI
# from src.config import Config
# from src.fetcher import fetch_arxiv_papers
# from src.filter import filter_papers_by_topics
# from src.summarizer import generate_summaries
# from src.formatter import format_as_markdown, save_to_file


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ daily-arXiv å¯åŠ¨ä¸­...\n")

    start_time = time.time()

    try:
        # 1. åŠ è½½é…ç½®
        print("ğŸ“‹ æ­£åœ¨åŠ è½½é…ç½®...")
        # TODO: å®ç°é…ç½®åŠ è½½
        # config = Config()
        # config.validate()
        print("  âœ… é…ç½®åŠ è½½æˆåŠŸ")
        print(f"  - ç ”ç©¶æ¯é¢˜æ•°é‡ï¼šTODO")
        print(f"  - arXiv ç±»åˆ«ï¼šTODO")
        print()

        # 2. çˆ¬å–è®ºæ–‡
        print("ğŸ“¥ æ­£åœ¨çˆ¬å– arXiv è®ºæ–‡...")
        # TODO: å®ç°è®ºæ–‡çˆ¬å–
        # papers = fetch_arxiv_papers(
        #     config.arxiv_categories,
        #     config.max_papers_per_category
        # )
        print(f"  âœ… æˆåŠŸçˆ¬å– TODO ç¯‡è®ºæ–‡\n")

        # 3. æ¯é¢˜ç­›é€‰
        print("ğŸ” æ­£åœ¨è¿›è¡Œæ¯é¢˜ç­›é€‰...")
        # TODO: å®ç°æ¯é¢˜ç­›é€‰
        # llm_client = OpenAI(api_key=config.api_key, base_url=config.base_url)
        # filtered_papers = filter_papers_by_topics(
        #     papers,
        #     config.research_topics,
        #     llm_client
        # )
        print(f"  âœ… ç­›é€‰å®Œæˆï¼Œä¿ç•™ TODO ç¯‡è®ºæ–‡\n")

        # 4. ç”Ÿæˆæ‘˜è¦
        print("ğŸ“ æ­£åœ¨ç”Ÿæˆä¸­æ–‡æ‘˜è¦...")
        # TODO: å®ç°æ‘˜è¦ç”Ÿæˆ
        # summarized_papers = generate_summaries(filtered_papers, llm_client)
        print(f"  âœ… æ‘˜è¦ç”Ÿæˆå®Œæˆ\n")

        # 5. æ ¼å¼åŒ–è¾“å‡º
        print("ğŸ’¾ æ­£åœ¨ä¿å­˜ç»“æœ...")
        # TODO: å®ç°è¾“å‡ºæ ¼å¼åŒ–
        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        # stats = {
        #     "total_papers": len(papers),
        #     "filtered_papers": len(filtered_papers),
        #     "filter_rate": len(filtered_papers) / len(papers) * 100,
        #     "total_cost": sum(p.total_tokens for p in summarized_papers) / 1000 * 0.001,
        #     "runtime": format_runtime(time.time() - start_time),
        # }
        #
        # md_content = format_as_markdown(summarized_papers, stats)
        # output_path = save_to_file(md_content, config.output_dir)
        output_path = "TODO"
        print(f"  âœ… å·²ä¿å­˜åˆ°ï¼š{output_path}\n")

        # 6. æ˜¾ç¤ºæ‘˜è¦
        print("=" * 60)
        print("ğŸ“Š è¿è¡Œæ‘˜è¦")
        print("=" * 60)
        print(f"çˆ¬å–è®ºæ–‡ï¼šTODO ç¯‡")
        print(f"ç­›é€‰åï¼šTODO ç¯‡ï¼ˆç­›é€‰ç‡ï¼šTODO%ï¼‰")
        print(f"æˆæœ¬ï¼šÂ¥TODO")
        print(f"è¿è¡Œæ—¶é—´ï¼šTODO")
        print("=" * 60)

    except FileNotFoundError as e:
        print(f"âŒ é…ç½®æ–‡ä»¶ç¼ºå¤±ï¼š{e}")
        print("\nğŸ’¡ è§£å†³æ–¹æ³•ï¼š")
        print("  1. å¤åˆ¶ config/.env.example ä¸º config/.env")
        print("  2. åœ¨ .env ä¸­é…ç½®ä½ çš„ API å¯†é’¥")
        print("  3. åœ¨ config/research_topics.txt ä¸­æ·»åŠ ç ”ç©¶æ¯é¢˜")
        return

    except ValueError as e:
        print(f"âŒ é…ç½®é”™è¯¯ï¼š{e}")
        return

    except ConnectionError as e:
        print(f"âŒ ç½‘ç»œè¿æ¥å¤±è´¥ï¼š{e}")
        print("\nğŸ’¡ è§£å†³æ–¹æ³•ï¼š")
        print("  1. æ£€æŸ¥ç½‘ç»œè¿æ¥")
        print("  2. å¦‚æœä½¿ç”¨ä»£ç†ï¼Œè¯·ç¡®ä¿ä»£ç†é…ç½®æ­£ç¡®")
        return

    except Exception as e:
        print(f"âŒ æœªçŸ¥é”™è¯¯ï¼š{e}")
        import traceback
        traceback.print_exc()
        return


def format_runtime(seconds: float) -> str:
    """æ ¼å¼åŒ–è¿è¡Œæ—¶é—´"""
    minutes = int(seconds // 60)
    secs = int(seconds % 60)
    return f"{minutes} åˆ† {secs} ç§’"


if __name__ == "__main__":
    main()
